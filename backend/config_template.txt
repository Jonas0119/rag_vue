# 环境变量配置模板
# 使用说明：将此文件复制为 .env 文件，并填入实际配置值
# 命令（在 backend 目录下）：cp config_template.txt .env

# ==================== API 配置 ====================
# MiniMax API（通过 Anthropic 接口）
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_BASE_URL=https://api.minimaxi.com/anthropic

# ==================== 存储模式切换 ====================
# local: 使用本地文件系统/SQLite/Chroma
# cloud: 使用云服务（Supabase/Pinecone）
STORAGE_MODE=local
VECTOR_DB_MODE=local
DATABASE_MODE=local

# ==================== 本地存储配置（STORAGE_MODE=local 时使用）====================
DATA_ROOT_DIR=data
USER_DATA_DIR=data/users
CHROMA_DB_DIR=data/chroma
DATABASE_PATH=data/database/rag_system.db
MAX_FILE_SIZE=20971520

# ==================== Supabase 配置 ====================
# 获取方式：Supabase Dashboard -> Settings -> API
SUPABASE_URL=https://your-project-ref.supabase.co
SUPABASE_KEY=your_publishable_key
SUPABASE_SERVICE_KEY=your_service_key

# Supabase Storage
SUPABASE_STORAGE_BUCKET=rag

# Supabase PostgreSQL
# 获取方式：Supabase Dashboard -> Settings -> Database -> Connection string
# 格式：postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].supabase.co:5432/postgres
DATABASE_URL=postgresql://postgres:your_password@db.your-project-ref.supabase.co:5432/postgres

# ==================== Pinecone 配置 ====================
# 获取方式：Pinecone Dashboard -> API Keys
PINECONE_API_KEY=your_pinecone_api_key

# Pinecone Environment/Region
# 免费版通常是：us-east-1 (AWS) 或 us-east1-gcp (GCP)
PINECONE_ENVIRONMENT=us-east-1

# Pinecone Index 名称（单 Index，所有用户共享）
PINECONE_INDEX_NAME=rag-system

# ==================== 认证配置 ====================
# Streamlit Authenticator
AUTH_COOKIE_NAME=rag_auth_token
AUTH_COOKIE_KEY=generate_with_command_below
AUTH_COOKIE_EXPIRY_DAYS=30

# 生成随机密钥的命令：
# python -c "import secrets; print(secrets.token_urlsafe(32))"

# 密码强度要求
MIN_PASSWORD_LENGTH=6

# ==================== 消息总结配置 ===================
# 启用自动消息总结（当消息总 token 数超过阈值时自动总结历史消息）
USE_MESSAGE_SUMMARIZATION=true
# 触发总结的 token 阈值（默认 8000）
MESSAGE_SUMMARIZATION_THRESHOLD=8000
# 总结后保留的最近消息数量（默认 20）
MESSAGE_SUMMARIZATION_KEEP_MESSAGES=20
# 可选：使用专门的总结模型（如果为空，则使用主模型）
# 可以使用更便宜的模型进行总结，例如：gpt-4o-mini
# MESSAGE_SUMMARIZATION_MODEL=gpt-4o-mini
# 总结的最大 token 数（默认 500）
MESSAGE_SUMMARIZATION_MAX_TOKENS=500

# ==================== RAG 配置 ====================
# 文本分块
CHUNK_SIZE=800
CHUNK_OVERLAP=100
MIN_CHUNK_SIZE=200
MAX_CHUNK_SIZE=1000

# 向量检索
RETRIEVAL_K=3
RETRIEVAL_SEARCH_TYPE=similarity

# RAG 降级配置
# 当没有找到相关文档或相似度太低时，是否使用大模型直接回答
RAG_FALLBACK_ENABLED=true
# 相似度阈值（0-1之间），低于此值将使用直接回答模式
RAG_SIMILARITY_THRESHOLD=0.3

# LLM 参数
LLM_MODEL=MiniMax-M2
LLM_TEMPERATURE=0
LLM_MAX_TOKENS=2000

# Embedding 模型
EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5
EMBEDDING_DEVICE=cpu
NORMALIZE_EMBEDDINGS=true
# 模型下载源：huggingface 或 modelscope（默认使用 modelscope）
# modelscope: 使用 ModelScope SDK 下载模型到默认缓存目录（~/.cache/modelscope/hub/）
# huggingface: 直接从 HuggingFace 下载模型
MODEL_DOWNLOAD_SOURCE=modelscope

# ==================== Streamlit 配置 ====================
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0

# ==================== 日志配置 ====================
LOG_LEVEL=INFO
LOG_FILE=logs/app.log

